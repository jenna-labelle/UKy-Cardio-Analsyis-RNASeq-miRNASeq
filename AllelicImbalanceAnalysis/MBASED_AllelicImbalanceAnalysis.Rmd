---
title: "R Notebook"
output: html_notebook
---

#Allele imbalance analysis- MBASED beta-binomial testing  

Using allele counts from ASEReadCounter as input

Import libraries
```{r}
library(MBASED)
library(dplyr)
suppressPackageStartupMessages(library(TxDb.Hsapiens.UCSC.hg19.knownGene))
```

Functions
```{r}
#Summarize results from mbased
summarizeASEResults_1s <- function(MBASEDOutput) {
  geneOutputDF <- data.frame(majorAlleleFrequency=assays(MBASEDOutput)$majorAlleleFrequency[,1],
                             pValueASE=assays(MBASEDOutput)$pValueASE[,1],
                             pValueHeterogeneity=assays(MBASEDOutput)$pValueHeterogeneity[,1])
  lociOutputGR <- rowRanges(metadata(MBASEDOutput)$locusSpecificResults)
  lociOutputGR$allele1IsMajor <- assays(metadata(MBASEDOutput)$locusSpecificResults)$allele1IsMajor[,1]
  lociOutputGR$MAF <- assays(metadata(MBASEDOutput)$locusSpecificResults)$MAF[,1]
  lociOutputList <- split(lociOutputGR, factor(lociOutputGR$aseID, levels=unique(lociOutputGR$aseID)))
  return(list(geneOutput=geneOutputDF,
              locusOutput=lociOutputList))
}

#read in VCF, reformat and calculate allelic expression values (AE values not used here)
AllelicExpressionFromASEReadCounter<- function(File,  genes, TotalCoverage, RefCoverage, AltCoverage, NVariantsPerGene){
  #read in data, rename and remove unneeded columns
  vcf<- read.table(File)
  colnames(vcf)<- c("seqnames", "start", "end", "ID", "Ref", "Alt", "RefDepth", "AltDepth",
                    "Coverage", "lowMAPQDepth","lowBaseQDepth","rawDepth", "otherBases","improperPairs")
  vcf<-vcf[,!(colnames(vcf) %in% c("lowMAPQDepth", "lowBaseQDepth", "rawDepth", "improperPairs"))]

  #convert to granges object
  vcf_gr<- makeGRangesFromDataFrame(vcf, keep.extra.columns = TRUE)
    
  #Get the geneID names, associate back with the GRanges object
  hits<- findOverlaps(vcf_gr, genes)
  geneid <- CharacterList(split(genes$gene_id[subjectHits(hits)],queryHits(hits)))
  mcols(vcf_gr) <- DataFrame(mcols(vcf_gr), geneid)
  Junctions_GeneIDs<- as.data.frame(vcf_gr)
  
  #Calculate minor allele ratio and allelic expression (abs(0.5-minor allele ratio))
  Junctions_GeneIDs$MAF<- Junctions_GeneIDs$AltDepth/Junctions_GeneIDs$Coverage
  Junctions_GeneIDs$AllelicExpression<- abs(0.5-Junctions_GeneIDs$MAF)
  
  #Subset by SNPs that meet coverage/quality thresholds
  TotalCoverageFilter<- Junctions_GeneIDs[Junctions_GeneIDs$Coverage>=TotalCoverage,]
  RefCoverageFilter<- TotalCoverageFilter[TotalCoverageFilter$RefDepth>=RefCoverage,]
  AltCoverageFilter<- RefCoverageFilter[RefCoverageFilter$AltDepth>=AltCoverage,]

  
  #subset by genes with at least n variants
  AltCoverageFilter$geneid<-as.character(AltCoverageFilter$geneid)
  NVariants<- AltCoverageFilter%>% group_by(geneid) %>% mutate(NumberVariantsPerGene=n()) %>% as.data.frame()
  NVariantsFilter<- NVariants[NVariants$NumberVariantsPerGene>=NVariantsPerGene,]
    
  #median of these ratios for genes
  MedianRatios<- NVariantsFilter %>% group_by(geneid) %>% mutate(MedianAllelicExpression=median(AllelicExpression)) %>% as.data.frame
  MedianRatios<- MedianRatios[order(MedianRatios$geneid),]
  
  
  return(MedianRatios)
  
}

#Add ID unique to that SNP (chr, location, ref/alt)
AddUniqueSNPID<- function(df){
  df$SNPID<- paste(df$seqnames, ":", df$start, "_", df$Ref, "/", df$Alt, sep="")
  return(df)
}



GetMaxofWeirdList<- function(WeirdList){
  return(max(as.integer(unlist(strsplit(as.character(WeirdList), ",")))))
}

#Reformat, convert to summarized experiment (required for MBASED)
ConvertToSE_MBASEDInput<- function(SNVs){
  #subset and rename
  SNVs<-SNVs[,colnames(SNVs) %in% c("seqnames", "start", "end", "Ref", "Alt", "RefDepth", "AltDepth", "geneid")]
  colnames(SNVs)<-c("seqnames", "start", "end", "Ref", "Alt", "allele1", "allele2", "aseID")
  
  #Add unique column for each snp- geneid_Number
  SNVs<-SNVs %>% group_by(aseID) %>% mutate(ID=paste(aseID, 1:n(),sep="_")) %>% as.data.frame
  
  #Convert to granges
  SNVs_gr<- makeGRangesFromDataFrame(SNVs, keep.extra.columns = TRUE)
  names(SNVs_gr)<-SNVs_gr$ID
  
  #Create summarized experiment with info on allelic depth
  se<-SummarizedExperiment(
    assays=list(
      lociAllele1Counts=matrix(
        SNVs_gr$allele1,
        ncol=1,
        dimnames=list(names(SNVs_gr),'mySample')),
      lociAllele2Counts=matrix(
        SNVs_gr$allele2,
        ncol=1,
        dimnames=list(names(SNVs_gr), "mySample"))),
    rowRanges=SNVs_gr
      )
  
  return(se)

}

#run MBASES, extract and summarize results
GetMBASEDResults<- function(se, numsim){
 #run MBASED
  ASEresults <- runMBASED(
  ASESummarizedExperiment=se,
  isPhased=TRUE,
  numSim=numsim,
  BPPARAM = SerialParam()
 )
  
  ##Get results
  results<-as.data.frame(assays(ASEresults)$pValueASE)
  results$gene<-rownames(results)
  results$MajorAlleleFreq<-as.numeric(assays(ASEresults)$majorAlleleFrequency)
  sig_results<-results

  print(paste("Tested genes:", nrow(sig_results)))
  return(sig_results)

}

```



#Read in allelic depth counts: from ASEReadCounter
```{r}
#read in txdb+genes- used for annotation
txdb <- TxDb.Hsapiens.UCSC.hg19.knownGene
genes <- genes(TxDb.Hsapiens.UCSC.hg19.knownGene)

#Samples to read in
files=c("1", "2", "3", "4", "5", "6", "7", "8", "9", "11", "12", "13", "15", "16", "17", "18", "19", paste("Control", 1:5, sep="") )

#File paths to ASEReadCounter output files (already filtered by GOI)
filepaths=paste("D:/UKy/PostWASP_AlleleCounts/", "GOIIntersect_Reformated_ASECounts_", files, ".txt", sep="")

#read in filepaths, calculate allelic depth + add geneID info + coverage filters  
mySNVs<- lapply(filepaths, AllelicExpressionFromASEReadCounter, genes, 15,2,2,3)
```

#Read in exome data
```{r}

#Read in for exome vcf data- CM genes
wd<-"D:/UKy/Exome_Vcf/CMGenesROI_AllelicDepth/" #Set working directory
Samples<- c(1:3,5:19) #Samples to be read in
Files<- paste(wd, "AllelicDepth_GOIFilteredvcf_HeaderRemoved_Tube-", Samples, "-clean.snp.txt",sep="") #set file names
CM_AllAllelicExpression_Exome<-lapply(Files, read.table)

#Read in for exome vcf data- Non CM genes
wd<-"D:/UKy/Exome_Vcf/NonCMGenesROI_AllelicDepth/" #Set working directory
Samples<- c(1:3,5:19) #Samples to be read in
Files<- paste(wd, "AllelicDepth_GOIFilteredvcf_HeaderRemoved_Tube-", Samples, "-clean.snp.txt",sep="") #set file names
NonCM_AllAllelicExpression_Exome<-lapply(Files, read.table)

#Merge CM and nonCM into one list
AllAllelicExpression_Exome<-Map(rbind, CM_AllAllelicExpression_Exome, NonCM_AllAllelicExpression_Exome) 

#name columns correctly
AllAllelicExpression_Exome_Renamed<-list()
for (i in 1:length(AllAllelicExpression_Exome)){
  df<-AllAllelicExpression_Exome[[i]]
  colnames(df)<- c("seqnames", "start", "ID", "Ref", "Alt", "Score", "Qual", "V8", "V9" )
  AllAllelicExpression_Exome_Renamed[[i]]<-df
}


```

#Extra filtering of ASEReadCounter allele counts: filter by exome SNPs
```{r}
#Add column to all variants (in exome and RNASeq data) with unique SNP ID
Exome_UniqueSNPID<-lapply(AllAllelicExpression_Exome_Renamed, AddUniqueSNPID)
RNA_UniqueSNPID<- lapply(mySNVs, AddUniqueSNPID)

#Combine all variants into one list
Exome_ScoreSNP<- lapply(Exome_UniqueSNPID, function(x) {x[,c(6,10)]})
multi_full<- do.call(rbind,Exome_ScoreSNP)

#Get just unique variants (i.e., get rid of duplicates). Keep the SNP with the highest score (for if I ever want to do extra filtering based on score)
Exome_AllSNPs <- multi_full[order(multi_full[,'SNPID'],-multi_full[,'Score']),]
Exome_AllSNPs<- Exome_AllSNPs[!duplicated(Exome_AllSNPs$SNPID),] 

#Filter RNASeq variants based on filtered exome variants
RNA_VariantsInExome<- lapply(RNA_UniqueSNPID, function(x) {x[x$SNPID %in% Exome_AllSNPs$SNPID,]}) 
```

#Extra Filter 2: Alt/Ref coverage by PERCENTAGE OF TOTAL COVERAGE. This is in addition to the raw thresholds set when importing data
```{r}
RNA_VariantsInExome_Ref<- lapply(RNA_VariantsInExome, function(x){
  x[x$RefDepth>=round(x$Coverage*.1),]
})
RNA_VariantsInExome_Alt<- lapply(RNA_VariantsInExome_Ref, function(x){
  x[x$AltDepth>=round(x$Coverage*.1),]
}) 

```

```{r}
#Convert to summarized experiments- necessary for MBASED input  
allSE<- lapply(RNA_VariantsInExome_Alt, ConvertToSE_MBASEDInput)
```




#Run MBASED
```{r}
set.seed(6) 

#Run MBASED and extract results
allMBASED<-lapply(allSE, GetMBASEDResults, 10^3)

#Create data frame of all samples/genes with their majorAllele frequencies
  allMBASED_MAF<-list()
  for (sample in 1:length(files)){
    df<- allMBASED[[sample]][,2:3]
    colnames(df)<- c("gene", files[sample])
    allMBASED_MAF[[sample]]<-df
  }
  
  #Merge results into one df
  allMAFs<- allMBASED_MAF %>% Reduce(function(dtf1,dtf2) full_join(dtf1,dtf2,by="gene"), .)
  rownames(allMAFs)<-allMAFs$gene
  allMAFs<-allMAFs[,!(colnames(allMAFs)=="gene")]

#Create data frame of all samples/genes with padj
  allMBASED_withSample<-list()
  for (sample in 1:length(files)){
    df<- allMBASED[[sample]][,1:2]
    colnames(df)<- c(files[sample], "gene")
    allMBASED_withSample[[sample]]<-df
  }
  
  #Merge results into one df
  allResults<- allMBASED_withSample %>% Reduce(function(dtf1,dtf2) full_join(dtf1,dtf2,by="gene"), .)
  rownames(allResults)<-allResults$gene
  allResults<-allResults[,!(colnames(allResults)=="gene")]

#write.csv(allResults, "C:/Users/jenna/OneDrive/Documents/UKy/MBASEDResults_PostWASP_ExomeFiltered_AllControls.csv")
```

#Multiple testing correction
```{r}
#Options for MTC
MTC<-c("bonferroni", "hochberg", "fdr")
adjusted<-apply(allResults,2,function(x){
        as.data.frame(p.adjust(na.omit(x), method=MTC[1], n=length(na.omit(x))))
})


#Rename columns correctly, add geneid column
adjusted_renamed<-list()
for (sample in 1:length(adjusted)){
        df<-adjusted[[sample]]
        df$gene<-rownames(df)
        colnames(df)<- c(files[sample], "gene")
        adjusted_renamed[[sample]]<-df
}

#Merge adjusted results into 1 df
adjusted_allResults<- adjusted_renamed %>% Reduce(function(dtf1,dtf2) full_join(dtf1,dtf2,by="gene"), .)
rownames(adjusted_allResults)<-adjusted_allResults$gene
adjusted_allResults<-adjusted_allResults[,!(colnames(adjusted_allResults)=="gene")]

adjusted_allResults[rownames(adjusted_allResults)=="7273",]
```

#Only keep genes that have sig AI (<0.01) in a CM sample and NO CONTROLS have sig AI (<0.01)
```{r}
#Subset to genes with sig AI in a CM sample
        #data frame of T/F/NA for each gene across all CM samples (<0.01)
        SigCMGenes<-as.data.frame(apply(adjusted_allResults[,1:17], 2, function(x){
                x<0.01
        }))

        #Replace NAs with FALSE
        CM_NAReplace<-SigCMGenes%>% mutate_each(funs(replace(., is.na(.), F))) 
        
        #Subset results to only keep genes with a TRUE in at least 1 CM sample
        SigCM_allResults<-adjusted_allResults[rowSums(CM_NAReplace)>=1,]

#Subset to genes with no sig AI in any controls

        #Subset by controls:
        controls_adjusted<-SigCM_allResults[,grep("Control", colnames(SigCM_allResults))]

        #True/False matrix for sig threshold
        controls_sig<-as.data.frame(apply(controls_adjusted,2, function(x){
                x<0.01
        }))

        #Replace NAs with FALSE
        controls_NAReplace<-controls_sig%>% mutate_each(funs(replace(., is.na(.), F))) 

        #Subset all samples by controls- only keep if all controls are below sig thresh
        adjusted_NotSiginControls<-SigCM_allResults[rowSums(controls_NAReplace)==0,]

#Convert ensembl ID to gene ID
adjusted_NotSiginControls<- adjusted_NotSiginControls[!(rownames(adjusted_NotSiginControls)=="c(\"100302152\", \"100506866\", \"7273\")"),]
rownames(adjusted_NotSiginControls)<- select(org.Hs.eg.db, rownames(adjusted_NotSiginControls), c("SYMBOL","ENTREZID"))$SYMBOL

#Write to csv
wd<-"C:/Users/jenna/OneDrive/Documents/UKy/"
#write.csv(adjusted_NotSiginControls, paste(wd, "MBASEDResults_15X2X_Exome_10Percent_Bonf_SiginCMNotInControls.csv",sep=""))
```

**Reformat results: Gene/Sample/padj/Control_padj/MAF/Control_MAF columns**
```{r}
SigAIReformat<-adjusted_NotSiginControls

#Split into controls/CM
SigAI_CM<-SigAIReformat[,grep("Control", colnames(SigAIReformat), invert=TRUE)]
SigAI_Controls<-SigAIReformat[,grep("Control", colnames(SigAIReformat))]

#Add column for gene ID
SigAI_CM$GeneID<- rownames(SigAI_CM)

#Melt CM df, rename columns
SigAI_CM_melt<-na.omit(melt(SigAI_CM))
colnames(SigAI_CM_melt)<-c("GeneID", "Sample", "Adjusted_pvalue")

#Remove any gene/samples without significant AI
SigAI_CM_sig<-SigAI_CM_melt[SigAI_CM_melt$Adjusted_pvalue<0.1,]

#Calculate mean adjusted p values for Control table
Mean_Control_padj<- as.data.frame(apply(SigAI_Controls, 1,function(x){mean(na.omit(x))}))
colnames(Mean_Control_padj)<-"MeanControlPadj"
Mean_Control_padj$GeneID<-rownames(Mean_Control_padj)

#Merge together
ControlCM_merged<- merge(SigAI_CM_sig, Mean_Control_padj, by="GeneID")

#Add in MAF information
  #Convert ensembl ID to gene ID
  allMAFs<- allMAFs[grep("c", rownames(allMAFs),invert=TRUE ),]
  rownames(allMAFs)<- select(org.Hs.eg.db, rownames(allMAFs), c("SYMBOL","ENTREZID"))$SYMBOL
  
  #Split MAF df into CM/controls
  MAF_CM<- allMAFs[,grep("Control", colnames(allMAFs), invert=TRUE)]
  MAF_Control<-allMAFs[,grep("Control", colnames(allMAFs))]
  
  #Melt MAF CM and add column for gene ID
  MAF_CM$geneID<- rownames(MAF_CM)
  MAF_CM_melt<-melt(MAF_CM)
  colnames(MAF_CM_melt)<- c("geneID", "Sample", "MajorAlleleFreq")
  
  #Add column with unique ID to MAF CM and padj data frame
  MAF_CM_melt$UniqueID<- paste(MAF_CM_melt$geneID, MAF_CM_melt$Sample, sep="_")
  ControlCM_merged$UniqueID<-paste(ControlCM_merged$GeneID, ControlCM_merged$Sample, sep="_")
  
  #Merge MAF CM info using Unique ID
  ControlCM_MAFCM<- merge(ControlCM_merged, MAF_CM_melt[,3:4], by="UniqueID")
  
  #Calculate median MAF for controls
  MeanControlMAF<- as.data.frame(apply(MAF_Control,1,function(x){mean(na.omit(x))}))
  colnames(MeanControlMAF)<-"MeanControlMajorAlleleFreq"
  MeanControlMAF$GeneID<- rownames(MeanControlMAF)
  
  #Merge mean control MAF using gene ID
  ControlCM_MAFCM_MAFControl<-merge(ControlCM_MAFCM, MeanControlMAF, by="GeneID")
  
```

**Export results**
```{r}
write.csv(ControlCM_merged, paste(wd, "SigAIResults_ControlCMPadj_092320.csv",sep=""))
```


#Get variants in sig AI genes, export
```{r}
#Add sample ID to variants
AllFilteredVariants_SigAI<-list()
count<-1
for (sample in 1:length(RNA_VariantsInExome_Alt)){
        df<-RNA_VariantsInExome_Alt[[sample]]
        df$Sample<-files[sample]
        AllFilteredVariants_SigAI[[count]]<-df
        count=count+1
}

#Merge into 1 df
AllFilteredVariants_SigAI_merge<-do.call("rbind", AllFilteredVariants_SigAI)
AllFilteredVariants_SigAI_merge$UniqueID<-paste(AllFilteredVariants_SigAI_merge$geneid,
                                                AllFilteredVariants_SigAI_merge$Sample, sep=":")

#Read in Sig AI results
wd<-"C:/Users/jenna/OneDrive/Documents/UKy/"
AI<- read.csv(paste(wd, "MBASEDResults_15X2X_Exome_10Percent_Bonf_SiginCMNotInControls.csv",sep=""), row.names = "X")

#Get unique IDs corresponding to sig AI genes
sigAI<-apply(AI, 1,function(x){
        names(x)[x<0.01]
})
genes<-names(sigAI)

#Add unique ID- Gene with AI + Sample
sigAI_UniqueID<-list()
count=1
for (i in 1:length(genes)){
        gene<-genes[i]
        samples<-unlist(unname(sigAI[i]))
        samples<-gsub("X", "", samples)
        sigAI_UniqueID[count]<-list(paste(gene, samples[!(is.na(samples))],sep=":"))
        count=count+1
}


#Select variants in gene/sample with sig AI
SigAIVariants<- AllFilteredVariants_SigAI_merge[AllFilteredVariants_SigAI_merge$UniqueID %in% unlist(sigAI_UniqueID),]

#write to csv
write.csv(SigAIVariants,paste(wd, "AllVariantsInSigAIGenes.csv",sep=""))
```

```{r}
sessionInfo()
```

