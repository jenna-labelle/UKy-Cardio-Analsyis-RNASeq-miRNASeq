---
title: "R Notebook"
output: html_notebook
---

Import libraries
```{r}
library(MBASED)
library(dplyr)
suppressPackageStartupMessages(library(TxDb.Hsapiens.UCSC.hg19.knownGene))
```

Functions
```{r}
#Summarize results from mbased
summarizeASEResults_1s <- function(MBASEDOutput) {
  geneOutputDF <- data.frame(majorAlleleFrequency=assays(MBASEDOutput)$majorAlleleFrequency[,1],
                             pValueASE=assays(MBASEDOutput)$pValueASE[,1],
                             pValueHeterogeneity=assays(MBASEDOutput)$pValueHeterogeneity[,1])
  lociOutputGR <- rowRanges(metadata(MBASEDOutput)$locusSpecificResults)
  lociOutputGR$allele1IsMajor <- assays(metadata(MBASEDOutput)$locusSpecificResults)$allele1IsMajor[,1]
  lociOutputGR$MAF <- assays(metadata(MBASEDOutput)$locusSpecificResults)$MAF[,1]
  lociOutputList <- split(lociOutputGR, factor(lociOutputGR$aseID, levels=unique(lociOutputGR$aseID)))
  return(list(geneOutput=geneOutputDF,
              locusOutput=lociOutputList))
}

#read in VCF, reformat and calculate allelic expression values (AE values not used here)
AllelicExpressionFromASEReadCounter<- function(File,  genes, TotalCoverage, RefCoverage, AltCoverage, NVariantsPerGene){
  #read in data, rename and remove unneeded columns
  vcf<- read.table(File)
  colnames(vcf)<- c("seqnames", "start", "end", "ID", "Ref", "Alt", "RefDepth", "AltDepth",
                    "Coverage", "lowMAPQDepth","lowBaseQDepth","rawDepth", "otherBases","improperPairs")
  vcf<-vcf[,!(colnames(vcf) %in% c("lowMAPQDepth", "lowBaseQDepth", "rawDepth", "improperPairs"))]

  #convert to granges object
  vcf_gr<- makeGRangesFromDataFrame(vcf, keep.extra.columns = TRUE)
    
  #Get the geneID names, associate back with the GRanges object
  hits<- findOverlaps(vcf_gr, genes)
  geneid <- CharacterList(split(genes$gene_id[subjectHits(hits)],queryHits(hits)))
  mcols(vcf_gr) <- DataFrame(mcols(vcf_gr), geneid)
  Junctions_GeneIDs<- as.data.frame(vcf_gr)
  
  #Calculate minor allele ratio and allelic expression (abs(0.5-minor allele ratio))
  Junctions_GeneIDs$MAF<- Junctions_GeneIDs$AltDepth/Junctions_GeneIDs$Coverage
  Junctions_GeneIDs$AllelicExpression<- abs(0.5-Junctions_GeneIDs$MAF)
  
  #Subset by SNPs that meet coverage/quality thresholds
  TotalCoverageFilter<- Junctions_GeneIDs[Junctions_GeneIDs$Coverage>=TotalCoverage,]
  RefCoverageFilter<- TotalCoverageFilter[TotalCoverageFilter$RefDepth>=RefCoverage,]
  AltCoverageFilter<- RefCoverageFilter[RefCoverageFilter$AltDepth>=AltCoverage,]

  
  #subset by genes with at least n variants
  AltCoverageFilter$geneid<-as.character(AltCoverageFilter$geneid)
  NVariants<- AltCoverageFilter%>% group_by(geneid) %>% mutate(NumberVariantsPerGene=n()) %>% as.data.frame()
  NVariantsFilter<- NVariants[NVariants$NumberVariantsPerGene>=NVariantsPerGene,]
    
  #median of these ratios for genes
  MedianRatios<- NVariantsFilter %>% group_by(geneid) %>% mutate(MedianAllelicExpression=median(AllelicExpression)) %>% as.data.frame
  MedianRatios<- MedianRatios[order(MedianRatios$geneid),]
  
  
  return(MedianRatios)
  
}

#Add ID unique to that SNP (chr, location, ref/alt)
AddUniqueSNPID<- function(df){
  df$SNPID<- paste(df$seqnames, ":", df$start, "_", df$Ref, "/", df$Alt, sep="")
  return(df)
}



GetMaxofWeirdList<- function(WeirdList){
  return(max(as.integer(unlist(strsplit(as.character(WeirdList), ",")))))
}

#Reformat, convert to summarized experiment (required for MBASED)
ConvertToSE_MBASEDInput<- function(SNVs){
  #subset and rename
  SNVs<-SNVs[,colnames(SNVs) %in% c("seqnames", "start", "end", "Ref", "Alt", "RefDepth", "AltDepth", "geneid")]
  colnames(SNVs)<-c("seqnames", "start", "end", "Ref", "Alt", "allele1", "allele2", "aseID")
  
  #Add unique column for each snp- geneid_Number
  SNVs<-SNVs %>% group_by(aseID) %>% mutate(ID=paste(aseID, 1:n(),sep="_")) %>% as.data.frame
  
  #Convert to granges
  SNVs_gr<- makeGRangesFromDataFrame(SNVs, keep.extra.columns = TRUE)
  names(SNVs_gr)<-SNVs_gr$ID
  
  #Create summarized experiment with info on allelic depth
  se<-SummarizedExperiment(
    assays=list(
      lociAllele1Counts=matrix(
        SNVs_gr$allele1,
        ncol=1,
        dimnames=list(names(SNVs_gr),'mySample')),
      lociAllele2Counts=matrix(
        SNVs_gr$allele2,
        ncol=1,
        dimnames=list(names(SNVs_gr), "mySample"))),
    rowRanges=SNVs_gr
      )
  
  return(se)

}

#run MBASES, extract and summarize results
GetMBASEDResults<- function(se, numsim){
 #run MBASED
  ASEresults <- runMBASED(
  ASESummarizedExperiment=se,
  isPhased=TRUE,
  numSim=numsim,
  BPPARAM = SerialParam()
 )
  
  ##Get results
  results<-as.data.frame(assays(ASEresults)$pValueASE)
  results$gene<-rownames(results)
  sig_results<-results[results$mySample<0.05,]

  print(paste("Sig genes:", nrow(sig_results)))
  return(sig_results)

}

```



#Read in vcf --> allelic depth/basic filtering OR pre-filtered variants, based on exome
Two sources: raw VCF, or allelic depths calculated by ASEReadCounter

```{r}
#read in txdb+genes
txdb <- TxDb.Hsapiens.UCSC.hg19.knownGene
genes <- genes(TxDb.Hsapiens.UCSC.hg19.knownGene)

#Input option 1: Pre-filtered, based on exome
  #mySNVs<-read.csv("D:/UKy/MergingRNASeq/MergedRuns_vcf.gz/NonCM_GOIFiltered/MERGED_FinalFilteredVariants_PercentCoverageExome_AllCMVariants.csv",row.names="X", stringsAsFactors = FALSE)
  #mySNVs<-mySNVs[mySNVs$Sample=="2",]

#Input option 2: 

#Samples to read in
files=c("1", "2", "3", "4", "5", "6", "7", "8", "9", "11", "12", "13", "15", "16", "17", "18", "19")

#File paths to ASEReadCounter output files (already filtered by GOI)
filepaths=paste("D:/UKy/PostWASP_AlleleCounts/", "GOIIntersect_Reformated_ASECounts_", files, ".txt", sep="")

#read in filepaths, calculate allelic depth + add geneID info + coverage filters  
mySNVs<- lapply(filepaths, AllelicExpressionFromASEReadCounter, genes, 15,2,2,3)

```

#Read in exome data
```{r}
#Some preliminary filtering included here: 2x Ref and Alt coverage + >= 40 qual score

#Read in for exome vcf data- CM genes
wd<-"D:/UKy/Exome_Vcf/CMGenesROI_AllelicDepth/" #Set working directory
Samples<- c(1:3,5:19) #Samples to be read in
Files<- paste(wd, "AllelicDepth_GOIFilteredvcf_HeaderRemoved_Tube-", Samples, "-clean.snp.txt",sep="") #set file names
CM_AllAllelicExpression_Exome<-lapply(Files, AllelicExpressionFromVCF, GOIRanges=GOIRanges, 0,0,0,0,0)

#Read in for exome vcf data- Non CM genes
wd<-"D:/UKy/Exome_Vcf/NonCMGenesROI_AllelicDepth/" #Set working directory
Samples<- c(1:3,5:19) #Samples to be read in
Files<- paste(wd, "AllelicDepth_GOIFilteredvcf_HeaderRemoved_Tube-", Samples, "-clean.snp.txt",sep="") #set file names
NonCM_AllAllelicExpression_Exome<-lapply(Files, AllelicExpressionFromVCF, GOIRanges=NonCM_GOIRanges, 0,0,0,0,0)

#Merge CM and nonCM into one list
AllAllelicExpression_Exome<-Map(rbind, CM_AllAllelicExpression_Exome, NonCM_AllAllelicExpression_Exome) #26259 variants total
```

#Extra filtering of ASEReadCounter allele counts: filter by exome SNPs
```{r}
#Filter Step 1: exome variants
  #Add column to all variants (in exome and RNASeq data) with unique SNP ID
  Exome_UniqueSNPID<-lapply(AllAllelicExpression_Exome, AddUniqueSNPID)
  RNA_UniqueSNPID<- lapply(mySNVs, AddUniqueSNPID)
  
  #Combine all variants into one list
  Exome_ScoreSNP<- lapply(Exome_UniqueSNPID, function(x) {x[,c(9,19)]})
  multi_full<- do.call(rbind,Exome_ScoreSNP)
  
  #Get just unique variants (i.e., get rid of duplicates). Keep the SNP with the highest score (for if I ever want to do extra filtering based on score)
  Exome_AllSNPs <- multi_full[order(multi_full[,'SNPID'],-multi_full[,'Score']),]
  Exome_AllSNPs<- Exome_AllSNPs[!duplicated(Exome_AllSNPs$SNPID),] #6999 unique SNPs in controls
  
  #Filter RNASeq variants based on filtered exome variants
  RNA_VariantsInExome<- lapply(RNA_UniqueSNPID, function(x) {x[x$SNPID %in% Exome_AllSNPs$SNPID,]}) #4810 --> 310 variants in each sample (on average)
```


```{r}
#Convert to summarized experiments- necessary for MBASED input  
se<- ConvertToSE_MBASEDInput(RNA_VariantsInExome[[7]])
allSE<- lapply(RNA_VariantsInExome, ConvertToSE_MBASEDInput)
```

#Run MBASED
```{r}
#Run MBASED and extract results
allMBASED<-lapply(allSE, GetMBASEDResults, 10^3)

#Add sample ID column
allMBASED_withSample<-list()
for (sample in 1:length(files)){
  df<- allMBASED[[sample]]
  colnames(df)<- c( files[sample],"gene")
  allMBASED_withSample[[sample]]<-df
}

#Merge results into one df
allResults<- allMBASED_withSample %>% Reduce(function(dtf1,dtf2) full_join(dtf1,dtf2,by="gene"), .)

write.csv(allResults, "C:/Users/jenna/OneDrive/Documents/UKy/MBASEDResults_PostWASP_ExomeFiltered.csv")
```

